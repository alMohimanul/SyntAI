🧠 AI Research Agentic System – Draft Overview
🛰️ Agent1: Paper Crawler
Task:

Crawl and scrape research papers from sources like arXiv, bioRxiv, conference sites.

Extract metadata: title, authors, abstract, date, source link.

Store raw PDF and basic JSON per paper.

🔍 Agent2: Content Extractor
Task:

Parse PDFs to extract:

Abstract

Methodology section

Figures (especially architecture diagrams, flowcharts)

Tables (for benchmarks/comparison)

Use layout-aware parsing + OCR for image-heavy papers.

🧩 Agent3: Vision-Language Code Generator
Task:

Use VLM (e.g., GPT-4V, Gemini, LLaVA) to interpret methodology diagrams.

Generate PyTorch/TensorFlow skeletons from architecture images.

Annotate code with original paper references and layer mappings.

📊 Agent4: Benchmark Table Aggregator
Task:

Parse and normalize comparison tables from papers.

Align benchmarks across papers (e.g., same dataset, metric).

Build a unified master table with:

Dataset name

Model name

Metric scores

Paper source

Dataset link (if public)

🖼️ Frontend Module
Displays:

Summaries, architectures, and benchmark comparisons

Code generation previews

Dataset links and metadata

Search + filter by task, model, or dataset