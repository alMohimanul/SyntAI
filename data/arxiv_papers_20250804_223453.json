{
  "search_timestamp": "2025-08-04T22:34:53.923080",
  "total_papers": 2,
  "papers": [
    {
      "arxiv_id": "2508.00788v1",
      "title": "Do They Understand Them? An Updated Evaluation on Nonbinary Pronoun   Handling in Large Language Models",
      "authors": [
        "Xushuo Tang",
        "Yi Ding",
        "Zhengyi Yang",
        "Yin Chen",
        "Yongrui Gu",
        "Wenke Yang",
        "Mingchen Ju",
        "Xin Cao",
        "Yongfei Liu",
        "Wenjie Zhang"
      ],
      "abstract": "Large language models (LLMs) are increasingly deployed in sensitive contexts where fairness and inclusivity are critical. Pronoun usage, especially concerning gender-neutral and neopronouns, remains a key challenge for responsible AI. Prior work, such as the MISGENDERED benchmark, revealed significant limitations in earlier LLMs' handling of inclusive pronouns, but was constrained to outdated models and limited evaluations. In this study, we introduce MISGENDERED+, an extended and updated benchmark for evaluating LLMs' pronoun fidelity. We benchmark five representative LLMs, GPT-4o, Claude 4, DeepSeek-V3, Qwen Turbo, and Qwen2.5, across zero-shot, few-shot, and gender identity inference. Our results show notable improvements compared with previous studies, especially in binary and gender-neutral pronoun accuracy. However, accuracy on neopronouns and reverse inference tasks remains inconsistent, underscoring persistent gaps in identity-sensitive reasoning. We discuss implications, model-specific observations, and avenues for future inclusive AI research.",
      "methodology": [
        "Large language models (LLMs) are increasingly deployed in sensitive contexts where fairness and inclusivity are critical",
        "Prior work, such as the MISGENDERED benchmark, revealed significant limitations in earlier LLMs' handling of inclusive pronouns, but was constrained to outdated models and limited evaluations",
        "We discuss implications, model-specific observations, and avenues for future inclusive AI research"
      ],
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published_date": "2025-08-01T17:11:42Z",
      "updated_date": "2025-08-01T17:11:42Z",
      "pdf_url": "http://arxiv.org/pdf/2508.00788v1",
      "arxiv_url": "http://arxiv.org/abs/2508.00788v1",
      "downloaded": false,
      "pdf_filename": null
    },
    {
      "arxiv_id": "2508.00784v1",
      "title": "Unraveling Hidden Representations: A Multi-Modal Layer Analysis for   Better Synthetic Content Forensics",
      "authors": [
        "Tom Or",
        "Omri Azencot"
      ],
      "abstract": "Generative models achieve remarkable results in multiple data domains, including images and texts, among other examples. Unfortunately, malicious users exploit synthetic media for spreading misinformation and disseminating deepfakes. Consequently, the need for robust and stable fake detectors is pressing, especially when new generative models appear everyday. While the majority of existing work train classifiers that discriminate between real and fake information, such tools typically generalize only within the same family of generators and data modalities, yielding poor results on other generative classes and data domains. Towards a universal classifier, we propose the use of large pre-trained multi-modal models for the detection of generative content. Effectively, we show that the latent code of these models naturally captures information discriminating real from fake. Building on this observation, we demonstrate that linear classifiers trained on these features can achieve state-of-the-art results across various modalities, while remaining computationally efficient, fast to train, and effective even in few-shot settings. Our work primarily focuses on fake detection in audio and images, achieving performance that surpasses or matches that of strong baseline methods.",
      "methodology": [
        "Generative models achieve remarkable results in multiple data domains, including images and texts, among other examples",
        "Consequently, the need for robust and stable fake detectors is pressing, especially when new generative models appear everyday",
        "Towards a universal classifier, we propose the use of large pre-trained multi-modal models for the detection of generative content",
        "Effectively, we show that the latent code of these models naturally captures information discriminating real from fake",
        "Our work primarily focuses on fake detection in audio and images, achieving performance that surpasses or matches that of strong baseline methods"
      ],
      "categories": [
        "cs.AI"
      ],
      "published_date": "2025-08-01T17:07:00Z",
      "updated_date": "2025-08-01T17:07:00Z",
      "pdf_url": "http://arxiv.org/pdf/2508.00784v1",
      "arxiv_url": "http://arxiv.org/abs/2508.00784v1",
      "downloaded": false,
      "pdf_filename": null
    }
  ]
}